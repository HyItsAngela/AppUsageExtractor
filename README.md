# AppUsageExtractor

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
![Project Status](https://img.shields.io/badge/status-active%20development-yellow)

> [!NOTE]
> This project is currently under active development. Core functionality is implemented with ongoing improvements.

An end-to-end computer vision pipeline that detects smartphone app interfaces using YOLO object detection and extracts usage statistics through OCR text recognition.

![Pipeline Visualization](docs/pipeline_diagram.png)

## Table of Contents
- [Key Features](#-key-features)
- [Project Structure](#-project-structure)
- [Output Details](#-output-structure)
- [Model Information](#-model-information)
- [Installation](#-installation)
- [Usage](#-usage)

## ðŸ’¡ Key Features

### Detection & Recognition
- **YOLO v11 Detection**: Custom-trained model identifies:
  - App icons
  - App name text regions
  - Usage time displays
  - Device ID markers
- **OCR Processing**:
  - PaddleOCR text extraction
  - Multi-stage text correction
  - Fuzzy name matching
  - Usage time validation

### Layout Understanding
- **Smart Layout Analysis**:
  - Grid pattern recognition
  - Spatial relationship mapping
  - Reference line detection

### Output System
- **Multi-Format Outputs**:
  - CSV reports
  - SQL database storage
  - Organized folder structure
  - Debug visualizations (toggleable)

## ðŸ“‚ Project Structure
```text
SmartApp-Usage-Extractor/
â”œâ”€â”€ configs/           # Configuration templates
â”‚   â””â”€â”€ default.yaml
â”œâ”€â”€ data/              # Optional: For sample input images
â”‚   â””â”€â”€ samples/
â”‚       â””â”€â”€ sample_screenshot.jpg
â”œâ”€â”€ docs/              # Documentation
â”‚   â””â”€â”€ pipeline_diagram.png
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ args.yaml       # Training configuration
â”‚   â””â”€â”€ weights/        # Model parameters (Git LFS)
â”‚         â””â”€â”€ best.pt   
â”œâ”€â”€ results/           # Output directory
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ process_image.py
â”‚   â””â”€â”€ batch_process.py
â”œâ”€â”€ src/                # Core pipeline code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”œâ”€â”€ detection.py
â”‚   â”œâ”€â”€ image_utils.py
â”‚   â”œâ”€â”€ layout_analysis.py
â”‚   â”œâ”€â”€ ocr.py
â”‚   â”œâ”€â”€ output_handler.py
â”‚   â”œâ”€â”€ parsing.py
â”‚   â””â”€â”€ utils.py          # For shared utilities like logging setup         
â”œâ”€â”€ README.md          
â””â”€â”€ requirements.txt
```

## ðŸ’¾ Output Structure
```text
results/
â”œâ”€â”€ id_folders/
â”‚   â””â”€â”€ ID_OWL1234/             # Example folder for a specific ID
â”‚       â”œâ”€â”€ original_image.jpg  # Original input image
â”‚       â””â”€â”€ ocr_results.txt     # Extracted text results
â”œâ”€â”€ debug_visualizations/     # Optional: Contains images with bounding boxes if debug=true
â”‚   â””â”€â”€ debug_image_ID_OWL1234.jpg # Example debug output
â”œâ”€â”€ usage_report.csv          # Aggregated usage data in CSV format
â””â”€â”€ usage.db                  # Aggregated usage data in SQLite database
```


### CSV Report Example
```text
| device_id | total_usage |   Facebook   |   Snapchat   |    WhatsApp   |    Calendar   |
|-----------|-------------|--------------|--------------|---------------|---------------|
| OWL1234   | 4h 15m      | 2h 30m       | 1h 15m       | 30m           | 0m            |
| OWL5678   | 6h 22m      | 3h 45m       | 0h 45m       | 1h 12m        | 40m           |
| OWL9012   | 3h 08m      | 1h 15m       | 1h 30m       | 15m           | 8m            |
```

## ðŸ“Š Model Information
**Custom YOLO Model**

- Trained on 3,376 smartphone screenshots
- Classes: app_icon, app_name, app_usage, id
- mAP@0.5: 0.99
- Input resolution: 1040x1040
  
### Model Directory Structure
```text
models/
  â”œâ”€â”€ args.yaml     # Training configuration
  â””â”€â”€ weights/
    â””â”€â”€ best.pt   # Trained model weights (Tracked with Git LFS)
```

> [!IMPORTANT]
> The best.pt model weights file is managed using Git Large File Storage (LFS). Ensure you have Git LFS installed (git lfs install) before cloning to download the model file correctly.

> [!CAUTION] 
> âš  Current version Limitations:
> Needs to improve OCR accuracy for low quality images.

## ðŸ“¦ Installation
```bash
# 1. Clone with Git LFS for model weights
git lfs install
git clone https://github.com/HyItsAngela/SmartApp-Usage-Extractor
cd SmartApp-Usage-Extractor

# 2. Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/MacOS
# .venv\Scripts\activate  # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Optional: GPU acceleration for PaddleOCR
pip install paddlepaddle-gpu
```

## ðŸ›  Usage
```bash
# Process Single Image:
python scripts/process_image.py \
  --input sample.jpg \
  --output results/ \
  --config configs/default.yaml

# Process a Directory of Images (Batch Processing):
python scripts/batch_process.py \
  --input-dir path/to/screenshots/ \
  --output-dir results/ \
  --config configs/default.yaml \
  --batch-size 16 \

