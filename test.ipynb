{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e2083d",
   "metadata": {},
   "source": [
    "# Test App Usage Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfcbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/04/23 00:38:53] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/anh8878/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/anh8878/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/anh8878/.local/lib/python3.9/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/anh8878/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "from pipeline import ImageProcessor\n",
    "from detection import YOLODetector\n",
    "from ocr import PaddleOCRWrapper, TextCorrector\n",
    "from output import CSVGenerator\n",
    "\n",
    "detector = YOLODetector()\n",
    "ocr = PaddleOCRWrapper()\n",
    "json_path = Path(\"data/scraped_app_names-cleaned.json\") \n",
    "corrector = TextCorrector(json_path=json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7af54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "IMAGES_DIR = DATA_DIR / \"images\"  \n",
    "OUTPUT_DIR = Path(\"data\")\n",
    "DEBUG_DIR = OUTPUT_DIR / \"debug_visualizations\"\n",
    "\n",
    "IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DEBUG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "processor = ImageProcessor(\n",
    "    detector=detector,\n",
    "    ocr=ocr,\n",
    "    corrector=corrector,\n",
    "    output_folder=str(OUTPUT_DIR)  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61f403",
   "metadata": {},
   "source": [
    "## 1. Single Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e060cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d49491ceb044eb882d1693b68d2abd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Image:', options=('data/images/20221012_181259000_iOS.jpg', 'data/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_and_display(image_path):\n",
    "    image_path = Path(image_path)\n",
    "    result = processor.process_image(str(image_path), debug=True)\n",
    "    \n",
    "    debug_img_path = DEBUG_DIR / f\"debug_{image_path.name}\"\n",
    "    debug_img = cv2.imread(str(debug_img_path))\n",
    "    \n",
    "    if debug_img is not None:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(debug_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Debug image not found at: {debug_img_path}\")\n",
    "    \n",
    "    display(pd.DataFrame(result.extracted_data))\n",
    "    return result\n",
    "\n",
    "image_selector = widgets.Dropdown(\n",
    "    options=sorted([str(p) for p in IMAGES_DIR.glob(\"*.[pj][np]g\")]),\n",
    "    description=\"Select Image:\"\n",
    ")\n",
    "\n",
    "process_btn = widgets.Button(description=\"Process Image\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_process_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        process_and_display(image_selector.value)\n",
    "\n",
    "process_btn.on_click(on_process_click)\n",
    "display(widgets.VBox([image_selector, process_btn, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1abed7",
   "metadata": {},
   "source": [
    "## 2. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80466fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171a7780cf8d4c58a6bce547e86986a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='data/images', description='Input Directory:'), Button(description='Run Batch', styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_batch_processing(input_dir, config_path=\"configs/settings.yaml\"):\n",
    "    from tqdm.notebook import tqdm\n",
    "    import pandas as pd\n",
    "    from utils.config import load_config\n",
    "    \n",
    "    config = load_config(Path(config_path))\n",
    "    \n",
    "    csv_config = {\n",
    "        'required_columns': ['session_id', 'id', 'app_name', 'app_usage', 'total_usage'],\n",
    "        'error_value': '-1',\n",
    "        'time_format': 'compact'\n",
    "    }\n",
    "    \n",
    "    all_results = []\n",
    "    image_paths = list(Path(input_dir).glob(\"*.png\")) + list(Path(input_dir).glob(\"*.jpg\"))\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=\"Processing\"):\n",
    "        try:\n",
    "            result = processor.process_image(str(img_path))\n",
    "            all_results.extend(result.extracted_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path.name}: {str(e)}\")\n",
    "    \n",
    "    # Initialize CSVGenerator\n",
    "    csv_gen = CSVGenerator(csv_config)\n",
    "    csv_path = Path(config.output.csv_path)\n",
    "    csv_gen.generate({\"batch_run\": all_results}, str(csv_path))\n",
    "    \n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "batch_dir = widgets.Text(\n",
    "    value=str(IMAGES_DIR),\n",
    "    description=\"Input Directory:\",\n",
    "    disabled=False\n",
    ")\n",
    "run_batch_btn = widgets.Button(description=\"Run Batch\")\n",
    "batch_output = widgets.Output()\n",
    "\n",
    "def on_batch_click(b):\n",
    "    with batch_output:\n",
    "        clear_output()\n",
    "        df = run_batch_processing(batch_dir.value)\n",
    "        display(df.head())\n",
    "\n",
    "run_batch_btn.on_click(on_batch_click)\n",
    "display(widgets.VBox([batch_dir, run_batch_btn, batch_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f3e14a",
   "metadata": {},
   "source": [
    "## 3. Component-Level Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1c1df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba4e1496271485a857b61bacba7cf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='1h30m', description='Test Text:'), Dropdown(description='Region Type:', index=1, op…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_ocr_correction(text, region_type):\n",
    "    corrected, corrections = corrector.correct_text(text, region_type)\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Corrected: {corrected}\")\n",
    "    print(f\"Corrections Applied: {corrections}\")\n",
    "\n",
    "ocr_test_text = widgets.Text(\n",
    "    value=\"1h30m\",\n",
    "    description=\"Test Text:\"\n",
    ")\n",
    "ocr_test_type = widgets.Dropdown(\n",
    "    options=[\"app_name\", \"app_usage\"],\n",
    "    value=\"app_usage\",\n",
    "    description=\"Region Type:\"\n",
    ")\n",
    "ocr_test_btn = widgets.Button(description=\"Test OCR\")\n",
    "ocr_test_out = widgets.Output()\n",
    "\n",
    "def on_ocr_test(b):\n",
    "    with ocr_test_out:\n",
    "        clear_output()\n",
    "        test_ocr_correction(ocr_test_text.value, ocr_test_type.value)\n",
    "\n",
    "ocr_test_btn.on_click(on_ocr_test)\n",
    "display(widgets.VBox([ocr_test_text, ocr_test_type, ocr_test_btn, ocr_test_out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfacc1e",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed82383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75293e53bacf409e9a0fac9d5dc4cf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Image:', options=('data/images/20221012_181259000_iOS.jpg', 'data/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_detections(image_path):\n",
    "    img = cv2.imread(str(image_path))  \n",
    "    if img is None:\n",
    "        print(f\"Error: Could not read image at {image_path}\")\n",
    "        return\n",
    "    \n",
    "    detections = detector.detect(img)\n",
    "    \n",
    "    for det in detections:\n",
    "        cv2.rectangle(img, \n",
    "                     (det.x, det.y), \n",
    "                     (det.x + det.w, det.y + det.h), \n",
    "                     (0, 255, 0), 2)\n",
    "        cv2.putText(img, \n",
    "                   f\"{det.label} {det.confidence:.2f}\", \n",
    "                   (det.x, det.y - 10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Detected {len(detections)} objects\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "viz_selector = widgets.Dropdown(\n",
    "    options=sorted([str(p) for p in IMAGES_DIR.glob(\"*.[pj][np]g\")]), \n",
    "    description=\"Select Image:\"\n",
    ")\n",
    "\n",
    "viz_btn = widgets.Button(description=\"Show Detections\")\n",
    "viz_out = widgets.Output()\n",
    "\n",
    "def on_viz_click(b):\n",
    "    with viz_out:\n",
    "        clear_output()\n",
    "        show_detections(viz_selector.value)\n",
    "\n",
    "viz_btn.on_click(on_viz_click)\n",
    "display(widgets.VBox([viz_selector, viz_btn, viz_out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca259a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
